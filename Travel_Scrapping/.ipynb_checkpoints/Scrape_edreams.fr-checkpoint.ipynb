{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969dafb9-4181-4e72-b571-955c2be53b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.edreams.fr/travel/?mktportal=kayakC&utm_campaign=PAR-MAD-test&utm_content=u%7E6d9cDfIyN6U5g71euNTq_UvRYEo1pr-qCwpOPKWXVpeWwyWv7AfGg%3D%3D&utm_medium=partners&utm_source=kayak&utm_term=flight#results/type=R;dep=2023-11-21;from=PAR;to=MAD;ret=2023-11-28;internalSearch=true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db579377-548c-410d-82b9-5c22a2e3b9a1",
   "metadata": {},
   "source": [
    "# edreams.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1dbca9-609f-4d8b-b1bf-bebfc2a65b71",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f413ff6-6832-4294-b4ea-ea9edc003212",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Scrappe and Clean\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import re\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.common.service import Service\n",
    "from selenium.webdriver.common.service import Service\n",
    "from fake_useragent import UserAgent\n",
    "from urllib3.exceptions import NewConnectionError\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda753d1-dbd0-4a49-84a4-6943bbe63b71",
   "metadata": {},
   "source": [
    "## Scrappe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9348fa01-fc78-4545-a1dd-1763c9985ab9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (881383913.py, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\yskon\\AppData\\Local\\Temp\\ipykernel_11360\\881383913.py\"\u001b[1;36m, line \u001b[1;32m30\u001b[0m\n\u001b[1;33m    driver.get(f'https://www.edreams.fr/travel/?mktportal=kayakC&utm_campaign={ville1}-{ville2}-test&utm_content=u%7E6d9cDfIyN6U5g71euNTq_UvRYEo1pr-qCwpOPKWXVpeWwyWv7AfGg%3D%3D&utm_medium=partners&utm_source=kayak&utm_term=flight#results/type=R;dep={start_date.strftime(\"%Y-%m-%d\")};from={ville1};to={ville2};ret={end_date.strftime(\"%Y-%m-%d\")};internalSearch=true\u001b[0m\n\u001b[1;37m                                                                                                                                                                                                                                                                                                                                                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "\n",
    "villes = [\"BER\", \"PAR\", \"ROM\", \"MAD\", \"LON\", \"LIS\", \"AMS\", \"BRU\", \"DUB\", \"CPH\", \"OSL\", \"STO\", \"HEL\", \"REK\", \"MOW\", \"WAW\", \"PRG\", \"BUD\", \"VIE\", \"ATH\", \"BUH\", \"SOF\", \"BEG\", \"ZAG\", \"TIA\", \"SKP\", \"TGD\", \"PRN\", \"TLL\", \"RIX\", \"VNO\", \"KIV\", \"MSQ\", \"KBP\", \"KBP\", \"TBS\", \"EVN\", \"BAK\", \"ANK\", \"ECN\", \"MLA\", \"VAT\", \"MCM\", \"RMI\"]\n",
    "options = webdriver.FirefoxOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument(f'user-agent={user_agent}')\n",
    "\n",
    "all_data = []\n",
    "\n",
    "logging.basicConfig(filename='scraping.log', level=logging.ERROR)\n",
    "\n",
    "# Date initiale\n",
    "start_date = datetime(2023, 11, 22)\n",
    "end_date = datetime(2023, 11, 28)\n",
    "\n",
    "# Date finale (2 mois plus tard)\n",
    "end_date_final = datetime(2024, 1, 22)\n",
    "\n",
    "# Boucle sur les semaines\n",
    "while start_date <= end_date_final:\n",
    "    for i in range(0, len(villes), 2):\n",
    "        ville1 = villes[i]\n",
    "        ville2 = villes[i + 1]\n",
    "\n",
    "        print(f'Début scrape des villes {ville1} et {ville2} pour la semaine du {start_date.strftime(\"%Y-%m-%d\")} au {end_date.strftime(\"%Y-%m-%d\")}')\n",
    "\n",
    "        driver = webdriver.Firefox(options=options, executable_path='/path/to/geckodriver')\n",
    "        try:\n",
    "            driver.get(f'https://www.opodo.fr/travel/?locale=fr_FR#/results/type=R;buyPath=1007;from={ville1};to={ville2};dep{start_date.strftime(\"%Y-%m-%d\")};adults=1;direct=false;children=0;infants=0;internalSearch=false;collectionmethod=false;ret={end_date.strftime(\"%Y-%m-%d\")}\n",
    "')\n",
    "                      \n",
    "        except NewConnectionError:\n",
    "            logging.error(f'Could not establish connection for cities {ville1} and {ville2}, retrying...')\n",
    "            time.sleep(10)\n",
    "            try:\n",
    "                driver.get(f'https://www.opodo.fr/travel/?locale=fr_FR#/results/type=R;buyPath=1007;from={ville1};to={ville2};dep{start_date.strftime(\"%Y-%m-%d\")};adults=1;direct=false;children=0;infants=0;internalSearch=false;collectionmethod=false;ret={end_date.strftime(\"%Y-%m-%d\")}\n",
    "')\n",
    "            except Exception as e:\n",
    "                logging.error(f'Failed to scrape cities {ville1} and {ville2}: {e}')\n",
    "                driver.quit()\n",
    "                continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Fonction auxiliaire pour récupérer des données\n",
    "        def extract_data(element, xpath):\n",
    "            try:\n",
    "                data = element.find_element(By.XPATH, xpath).get_attribute('textContent')\n",
    "            except:\n",
    "                data = \"\"\n",
    "            return data\n",
    "        time.sleep(2)\n",
    "        # Récupérer le contenu des divs JWEO et xdW8 dans c3J0r-container\n",
    "        # Récupérer le contenu des éléments\n",
    "        voyages = driver.find_elements(By.XPATH, './/div[contains(@class, \"css-1x3sxzl-Box e17fzqxg0\")]')\n",
    "\n",
    "\n",
    "        for voyage in voyages:\n",
    "        # Récupérer le contenu des éléments pour chaque voyage\n",
    "            horaires = extract_data(voyage, './/div[@class=\"css-v0s8x5-BaseText-Body e8d0hso0\"]')\n",
    "            trajet = extract_data(voyage, './/div[@class=\"css-1y3uwjk-BaseText-Body e8d0hso0\"]')\n",
    "            type_trajet = extract_data(voyage, './/span[@class=\"css-1kh4dda-BaseText-Text ek4n60o0\"]')\n",
    "            durée_trajet = extract_data(voyage, './/span[@class=\"css-1mbgvvh-BaseText-Text ek4n60o0\"]')\n",
    "            prix = extract_data(voyage, './/span[@class=\"money-integer css-hqtcs8-BaseText-MoneyPart-DefaultPart e16uabde1\"]')\n",
    "            #type_voyage = extract_data(voyage, './/div[@class=\"css-1um4vyc-BaseText-Body e8d0hso0\"]')\n",
    "\n",
    "        # Imprimer les résultats pour chaque voyage\n",
    "            print(\"Horaires:\", horaires)\n",
    "            print(\"Trajet:\", trajet)\n",
    "            print(\"Type de trajet:\", type_trajet)\n",
    "            print(\"Temps de trajet:\", temps_trajet)\n",
    "            print(\"Prix:\", prix)\n",
    "            #print(\"Type de voyage:\", type_voyage)\n",
    "            print(\"========================================\")\n",
    "        # Fermeture du webdriver\n",
    "        driver.quit()\n",
    "\n",
    "    # Passer à la semaine suivante\n",
    "    start_date += timedelta(weeks=1)\n",
    "    end_date += timedelta(weeks=1)\n",
    "\n",
    "print('Fin du scraping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14dafb5-d3ae-4089-9fca-43443cf60175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
